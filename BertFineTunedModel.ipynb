{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertFineTunedModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgreT0jPz1NMn4Y75K7l8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a090890b51d475c902862c802d7f1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_221203abf07f437dbf4d58f60d947634",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ff2f65b306e4331bfe0dcde83a2d474",
              "IPY_MODEL_bd329779f1d1420bbc3812c8acfa755a"
            ]
          }
        },
        "221203abf07f437dbf4d58f60d947634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ff2f65b306e4331bfe0dcde83a2d474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c534297fd7e44968a1913a354d9e96f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d95fe2106684ac19bef61eafcee8403"
          }
        },
        "bd329779f1d1420bbc3812c8acfa755a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e737f70ec5b847cfa12ff422c6dea055",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 122kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41919e2aa1bf4ddd89159bf4475bb252"
          }
        },
        "8c534297fd7e44968a1913a354d9e96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d95fe2106684ac19bef61eafcee8403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e737f70ec5b847cfa12ff422c6dea055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41919e2aa1bf4ddd89159bf4475bb252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc0e00c5ec324c3899dae1c8405e291e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b86d5a732324b7e99438de54a081fc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6db0d6d4bac34375a0f0d56f4b215c2c",
              "IPY_MODEL_2eb477f6b22d4207875bd17e69db3f59"
            ]
          }
        },
        "8b86d5a732324b7e99438de54a081fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6db0d6d4bac34375a0f0d56f4b215c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3781158705614d7a8fe0ddb2048a2916",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4194c52c4954ff08f346b4f2dbe9f5c"
          }
        },
        "2eb477f6b22d4207875bd17e69db3f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a43ed86af044c6bb6f8d1e99d079ead",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 34.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4491a82ed68443c9733a95a0803e24c"
          }
        },
        "3781158705614d7a8fe0ddb2048a2916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4194c52c4954ff08f346b4f2dbe9f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a43ed86af044c6bb6f8d1e99d079ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4491a82ed68443c9733a95a0803e24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15ee76083efb407ab1ea23b26830dc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7f3dd22428848918395c5d5cfd3acba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71019052563e4993b499e3f2c9c37b91",
              "IPY_MODEL_eaa0f8777365489daf9bae1d36a98833"
            ]
          }
        },
        "d7f3dd22428848918395c5d5cfd3acba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71019052563e4993b499e3f2c9c37b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac3f993d8e014e6f90f6ac8297d0ba8a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42709b0e4f0647f3a19ea138ca837ccf"
          }
        },
        "eaa0f8777365489daf9bae1d36a98833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f013f94bb15e45c5813d7bc894839d31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.37MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1963c0537d014bfab69ecd55d52c3d54"
          }
        },
        "ac3f993d8e014e6f90f6ac8297d0ba8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42709b0e4f0647f3a19ea138ca837ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f013f94bb15e45c5813d7bc894839d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1963c0537d014bfab69ecd55d52c3d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07187c669ff640f9ab09392405e54b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84b304e39c8e456c906f583aabea80ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4017bd985ec14a8384096f9a51cd12e7",
              "IPY_MODEL_694f33291e4e401984c8ab4a23eb3995"
            ]
          }
        },
        "84b304e39c8e456c906f583aabea80ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4017bd985ec14a8384096f9a51cd12e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d71008e0a9a456ba1bdf9cf149e8c72",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16cd16ea629348bfbdfb6a27985d6ae2"
          }
        },
        "694f33291e4e401984c8ab4a23eb3995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ebd45efcffbf4c729e95bdd15b855122",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 816B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e050861fdbd4d0fb57b91a5e7d30cae"
          }
        },
        "2d71008e0a9a456ba1bdf9cf149e8c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16cd16ea629348bfbdfb6a27985d6ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebd45efcffbf4c729e95bdd15b855122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e050861fdbd4d0fb57b91a5e7d30cae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d88514b8956429b80528d5138ffe3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1792e3d96a4644f9a7889baa45079bc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97a1cc58d4ff4e80b553df13f38f5316",
              "IPY_MODEL_1616787c1dcd42b899c677556aec557a"
            ]
          }
        },
        "1792e3d96a4644f9a7889baa45079bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97a1cc58d4ff4e80b553df13f38f5316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc9f156e463a4f61bf17def31586de9f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae24d1ab44bc450c9babe30c144d65b7"
          }
        },
        "1616787c1dcd42b899c677556aec557a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a50407c6f9834cee876a68196ca59476",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:17&lt;00:00, 25.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c84f2751dc264e48a595e4a7dbddc388"
          }
        },
        "bc9f156e463a4f61bf17def31586de9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae24d1ab44bc450c9babe30c144d65b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a50407c6f9834cee876a68196ca59476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c84f2751dc264e48a595e4a7dbddc388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fb0e9f230084f7d9fd593fbee58ec87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_636cc26a25be4ed9880c4dbc1e66f3d7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50104508798d4e32acad55a8709a49d6",
              "IPY_MODEL_433527df27da4304b230f083968be94e"
            ]
          }
        },
        "636cc26a25be4ed9880c4dbc1e66f3d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "50104508798d4e32acad55a8709a49d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f0132cdbb5e410eb2d4eb2f90275c17",
            "_dom_classes": [],
            "description": "Epoch 3: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 17012,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17012,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26cf07f1ec2942b69a21cc5bf02a5352"
          }
        },
        "433527df27da4304b230f083968be94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7d7d9a735ca45aba9b0cfebd718f7b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17012/17012 [17:15&lt;00:00, 16.42it/s, loss=1.34, v_num=0]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eda409fdc94847c2aab715943ae3586a"
          }
        },
        "4f0132cdbb5e410eb2d4eb2f90275c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26cf07f1ec2942b69a21cc5bf02a5352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7d7d9a735ca45aba9b0cfebd718f7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eda409fdc94847c2aab715943ae3586a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roosvlc/DCWEB-SOBA/blob/main/BertFineTunedModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N1924tCz4F1",
        "outputId": "c4b05cff-6a67-44fa-aaf2-45d67819a008"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 31 09:20:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O74pA0j1d1Cp",
        "outputId": "ca7dd0a3-7080-4d66-b1fe-a5899247b6e8"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# Get the GPU device name.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1zSSDg8r5M0",
        "outputId": "13dfd80c-70c5-4109-8e54-57058ae8ff71"
      },
      "source": [
        "!pip install transformers\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import multiprocessing as mp\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "8a090890b51d475c902862c802d7f1b8",
            "221203abf07f437dbf4d58f60d947634",
            "5ff2f65b306e4331bfe0dcde83a2d474",
            "bd329779f1d1420bbc3812c8acfa755a",
            "8c534297fd7e44968a1913a354d9e96f",
            "4d95fe2106684ac19bef61eafcee8403",
            "e737f70ec5b847cfa12ff422c6dea055",
            "41919e2aa1bf4ddd89159bf4475bb252",
            "cc0e00c5ec324c3899dae1c8405e291e",
            "8b86d5a732324b7e99438de54a081fc7",
            "6db0d6d4bac34375a0f0d56f4b215c2c",
            "2eb477f6b22d4207875bd17e69db3f59",
            "3781158705614d7a8fe0ddb2048a2916",
            "c4194c52c4954ff08f346b4f2dbe9f5c",
            "5a43ed86af044c6bb6f8d1e99d079ead",
            "c4491a82ed68443c9733a95a0803e24c",
            "15ee76083efb407ab1ea23b26830dc4d",
            "d7f3dd22428848918395c5d5cfd3acba",
            "71019052563e4993b499e3f2c9c37b91",
            "eaa0f8777365489daf9bae1d36a98833",
            "ac3f993d8e014e6f90f6ac8297d0ba8a",
            "42709b0e4f0647f3a19ea138ca837ccf",
            "f013f94bb15e45c5813d7bc894839d31",
            "1963c0537d014bfab69ecd55d52c3d54"
          ]
        },
        "id": "FDf44mK4sPpu",
        "outputId": "6058b4cc-950a-4ac5-fe54-c789c133acfa"
      },
      "source": [
        "#TOKENIZE TEXT\n",
        "flatten = lambda t: [item for sublist in t for item in sublist]\n",
        "\n",
        "tok = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "print(MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a090890b51d475c902862c802d7f1b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc0e00c5ec324c3899dae1c8405e291e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15ee76083efb407ab1ea23b26830dc4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1PUhmkCsc8m",
        "outputId": "c1b95288-39fc-4903-bf54-7939df3b5842"
      },
      "source": [
        "#tokenize\n",
        "def tokenize(x):\n",
        "    return tok.encode(x)[1:-1]\n",
        "print(\"Data: tokenized\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: tokenized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZYMYQ81shA-",
        "outputId": "4bfebd6d-d5b5-42b7-fe68-93622f5940ab"
      },
      "source": [
        "#masking & batching\n",
        "def process(_n):\n",
        "    n = _n\n",
        "    size = math.ceil(len(n)*0.15)\n",
        "    indices = random.sample(range(len(n)), size)\n",
        "    replacement_prob = [True, True, True, True, True, True, True, True, False, False]\n",
        "    output = [-100]*len(n)\n",
        "    for index in indices:\n",
        "        output[index] = n[index]\n",
        "        if random.choice(replacement_prob):\n",
        "            n[index] = 103\n",
        "        else:\n",
        "            if random.choice([True, False]):\n",
        "                n[index] = random.randint(1010, 30500)\n",
        "    return (n, output)\n",
        "\n",
        "def batcher(ins, outs):\n",
        "    batchx, batchy, batchesx, batchesy, batchesmasks = [], [], [], [], []\n",
        "    for i in zip(ins, outs):\n",
        "        batchx.append(i[0])\n",
        "        batchy.append(i[1])\n",
        "        if len(batchx) == BATCH_SIZE:\n",
        "            maxlen = max([len(x) for x in batchx])\n",
        "            masks = [[1] * len(x) + [0] * (maxlen - len(x)) for x in batchx]\n",
        "            batchx = [x + [0] * (maxlen - len(x)) for x in batchx]\n",
        "            batchy = [x + [0] * (maxlen - len(x)) for x in batchy]\n",
        "            batchesx.append(batchx)\n",
        "            batchesy.append(batchy)\n",
        "            batchesmasks.append(masks)\n",
        "            batchx = []\n",
        "            batchy = []\n",
        "    return [batchesx, batchesy, batchesmasks]\n",
        "print(\"Data: masked & batched\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: masked & batched\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4M7xjeKtDBO",
        "outputId": "4f5d0289-fdca-483c-92b5-fb2173f97428"
      },
      "source": [
        "#save to disk\n",
        "real_data = list(set(flatten([x.split(\".\") for x in open(\"data_post_training20k\").read().split(\".\")])))\n",
        "print(len(real_data))\n",
        "random.shuffle(real_data)\n",
        "\n",
        "pool = mp.Pool()\n",
        "tokenized = list(tqdm(pool.imap(tokenize, real_data), total=len(real_data)))\n",
        "\n",
        "inputs = tokenized\n",
        "outputs = list(tqdm(pool.imap(process, tokenized), total=len(tokenized)))\n",
        "outputs.sort(key=lambda x: len(x[0]))\n",
        "\n",
        "inputs = [[101] + x[0] + [102] for x in outputs]\n",
        "outputs = [[-100] + x[1] + [-100] for x in outputs]\n",
        "\n",
        "batched = batcher(inputs, outputs)\n",
        "pickle.dump(batched, open(\"lblq_data.pkl\", \"wb\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "136103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 136103/136103 [01:12<00:00, 1866.93it/s]\n",
            "100%|██████████| 136103/136103 [00:12<00:00, 10791.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "21ouofbZwtO-",
        "outputId": "0cd915ce-3b9e-47cb-f6f9-b2af533f74a0"
      },
      "source": [
        "#training\n",
        "!pip install transformers\n",
        "!pip install pytorch-lightning\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "device = torch.device(dev)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from transformers import BertForMaskedLM\n",
        "print(\"done installing and importing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=c627629af78b667af963b9f5943fe92aa81e5fc334b8a31eecc4d828935f8306\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/01/5df6324efdc3f79025ea7eaf19478936c401a16dae4fd3fbd29f7d426974/pytorch_lightning-1.2.6-py3-none-any.whl (829kB)\n",
            "\u001b[K     |████████████████████████████████| 839kB 8.5MB/s \n",
            "\u001b[?25hCollecting PyYAML!=5.4.*,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 35.9MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/42/d984612cabf005a265aa99c8d4ab2958e37b753aafb12f31c81df38751c8/torchmetrics-0.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 58.6MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.28.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (54.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2020.12.5)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 60.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Building wheels for collected packages: PyYAML, future\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=66a0a4fb7b5e1f74c0d3baabd6b89633e79c17b8057dc3ee526fb842e74b7c28\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=2c5a7fd8b43be415222393a2453c5e0cf6ae2e3c6d2acf59487b50529095a98a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built PyYAML future\n",
            "Installing collected packages: PyYAML, torchmetrics, future, async-timeout, multidict, yarl, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-0.8.7 future-0.18.2 multidict-5.1.0 pytorch-lightning-1.2.6 torchmetrics-0.2.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n",
            "done installing and importing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-ozHV7zx8Rn",
        "outputId": "b1ccabc4-82d3-4a83-ee05-711fce9aae10"
      },
      "source": [
        "class PTDataset(Dataset):\n",
        "  #loading data\n",
        "    def __init__(self):\n",
        "        self.data = pickle.load(open(\"lblq_data.pkl\", \"rb\"))\n",
        "        idxs = list(range(len(self.data[0])))\n",
        "        random.shuffle(idxs)\n",
        "        self.data = [[x[i] for i in idxs] for x in self.data]\n",
        "        print(\"Loaded {} rows of data\".format(len(self.data[0])))\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [torch.tensor(x[idx]) for x in self.data]\n",
        "print(\"check\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHIu-Th1ywIf",
        "outputId": "bfc6d7cb-2bb1-4466-95a8-a469b0f77317"
      },
      "source": [
        "class BertRestPT(pl.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #open bert model \n",
        "        self.bert = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "#feed masks and data\n",
        "    def forward(self, x):\n",
        "        inp, out, mask = x\n",
        "        enc = self.bert(input_ids=inp, attention_mask=mask, labels=out)\n",
        "        return enc\n",
        "#running training steps\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        yhat = self(batch)\n",
        "        loss = yhat.loss\n",
        "        return {'loss': loss}\n",
        "#uses Adam optimizer for loss\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=5e-5, eps=1e-4)\n",
        "print(\"check\")\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541,
          "referenced_widgets": [
            "07187c669ff640f9ab09392405e54b9c",
            "84b304e39c8e456c906f583aabea80ac",
            "4017bd985ec14a8384096f9a51cd12e7",
            "694f33291e4e401984c8ab4a23eb3995",
            "2d71008e0a9a456ba1bdf9cf149e8c72",
            "16cd16ea629348bfbdfb6a27985d6ae2",
            "ebd45efcffbf4c729e95bdd15b855122",
            "3e050861fdbd4d0fb57b91a5e7d30cae",
            "5d88514b8956429b80528d5138ffe3ae",
            "1792e3d96a4644f9a7889baa45079bc7",
            "97a1cc58d4ff4e80b553df13f38f5316",
            "1616787c1dcd42b899c677556aec557a",
            "bc9f156e463a4f61bf17def31586de9f",
            "ae24d1ab44bc450c9babe30c144d65b7",
            "a50407c6f9834cee876a68196ca59476",
            "c84f2751dc264e48a595e4a7dbddc388",
            "0fb0e9f230084f7d9fd593fbee58ec87",
            "636cc26a25be4ed9880c4dbc1e66f3d7",
            "50104508798d4e32acad55a8709a49d6",
            "433527df27da4304b230f083968be94e",
            "4f0132cdbb5e410eb2d4eb2f90275c17",
            "26cf07f1ec2942b69a21cc5bf02a5352",
            "b7d7d9a735ca45aba9b0cfebd718f7b8",
            "eda409fdc94847c2aab715943ae3586a"
          ]
        },
        "id": "n_T--KraJo1z",
        "outputId": "9f726cdf-3114-4597-ca1f-81d7e0e08812"
      },
      "source": [
        "#Save post-trained data\n",
        "if __name__ == \"__main__\":\n",
        "    trainer = pl.Trainer(gpus=1, distributed_backend='ddp', max_epochs=4)\n",
        "    dataset = PTDataset()\n",
        "    dataloader = DataLoader(dataset,batch_size = None)\n",
        "\n",
        "    print(\"Loading model\")\n",
        "    model = BertRestPT()\n",
        "    print(\"Loaded model\")\n",
        "    trainer.fit(model, dataloader)\n",
        "    model.bert.save_pretrained(\"POST2\")\n",
        "print(\"bert model save\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded 17012 rows of data\n",
            "Loading model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07187c669ff640f9ab09392405e54b9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d88514b8956429b80528d5138ffe3ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Missing logger folder: /content/lightning_logs\n",
            "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name | Type            | Params\n",
            "-----------------------------------------\n",
            "0 | bert | BertForMaskedLM | 109 M \n",
            "-----------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "438.057   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fb0e9f230084f7d9fd593fbee58ec87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "bert model save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmqWX1VEOAkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0550f0b4-b093-432a-aee7-fb10e425b519"
      },
      "source": [
        "#Model is post-trained on domain-specific corpus,\n",
        "#Start fine-tuning bert by import the task you want to fine-tune BERT on\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load Post-Trained BERT model, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained('POST2', # Use the post-trained domain specific BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at POST2 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at POST2 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSbvX037ZoKM",
        "outputId": "33bff132-1b20-41ee-b2a8-e1ed4ee7cfb6"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSKk9vYdadov",
        "outputId": "0283fe20-8f78-46ae-bbfe-778da6869935"
      },
      "source": [
        "print('Loading restaurant review data...')\n",
        "file = open('/content/restData19', 'r')\n",
        "review = file.read()\n",
        "review = review.replace(\"\\n\\n\", ' ')\n",
        "reviews = review.split(\",|,\")\n",
        "sentences = []\n",
        "labels = []\n",
        "i = 0 \n",
        "for rev in reviews:\n",
        "  sen = rev.split(\",/,\")\n",
        "  sentences.append(sen[1])\n",
        "  labels.append(int(sen[0]))\n",
        "  i += 1\n",
        "file = open('/content/restData2', 'r')\n",
        "review1 = file.read()\n",
        "review1 = review1.replace(\"\\n\\n\", ' ')\n",
        "reviews2 = review1.split(\",|,\")\n",
        "i = 0 \n",
        "for rev in reviews2:\n",
        "  sen = rev.split(\",/,\")\n",
        "  sentences.append(sen[1])\n",
        "  labels.append(int(sen[0]))\n",
        "  i += 1\n",
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading restaurant review data...\n",
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo_TvYF1ZuI-"
      },
      "source": [
        "#Call optimizer that we want to use for training\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDBXtYAxaLAp",
        "outputId": "fb1af0f2-12ad-4c42-ddb7-5e61c5f9d93c"
      },
      "source": [
        "import time\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('POST2', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lfIodngaGM3",
        "outputId": "61805076-a841-4d86-aac5-22ce5500a089"
      },
      "source": [
        "import torch\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "start = time.time()\n",
        "labels = torch.tensor(labels)\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation = True,\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(\"Tijd: \", end-start, \"s\")\n",
        "print(str(len(input_ids)) + ' reviews are now tokenized and have appropriate format en length.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tijd:  242.51388359069824 s\n",
            "100000 reviews are now tokenized and have appropriate format en length.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do9LavwsaB7Z",
        "outputId": "b668ba17-e8be-48cf-f66d-284f116a2020"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90,000 training samples\n",
            "10,000 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrxLDY_IZ9DD",
        "outputId": "66ed5b48-43de-44e1-f99d-965548a925b0"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "joejoe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ukiu9NHZzlV",
        "outputId": "71b6a730-4e4e-41d3-cc45-087bc73634dc"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "print(\"check\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKChBjqVbnUi",
        "outputId": "3ea53ede-bfd2-4ce3-ffe4-55467192c5ae"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "print(\"check\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmHexoufbxei",
        "outputId": "ea89e4a4-a449-416c-c2e2-b15312aea1a1"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "print(\"double check\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "double check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grDvTzmqb3Rs",
        "outputId": "2ca51d54-f090-4280-c1a4-c98f82207c86"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "device = torch.device(dev)\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += outputs.loss\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  11,250.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  11,250.    Elapsed: 0:00:36.\n",
            "  Batch   120  of  11,250.    Elapsed: 0:00:54.\n",
            "  Batch   160  of  11,250.    Elapsed: 0:01:13.\n",
            "  Batch   200  of  11,250.    Elapsed: 0:01:31.\n",
            "  Batch   240  of  11,250.    Elapsed: 0:01:49.\n",
            "  Batch   280  of  11,250.    Elapsed: 0:02:07.\n",
            "  Batch   320  of  11,250.    Elapsed: 0:02:25.\n",
            "  Batch   360  of  11,250.    Elapsed: 0:02:43.\n",
            "  Batch   400  of  11,250.    Elapsed: 0:03:01.\n",
            "  Batch   440  of  11,250.    Elapsed: 0:03:19.\n",
            "  Batch   480  of  11,250.    Elapsed: 0:03:37.\n",
            "  Batch   520  of  11,250.    Elapsed: 0:03:55.\n",
            "  Batch   560  of  11,250.    Elapsed: 0:04:14.\n",
            "  Batch   600  of  11,250.    Elapsed: 0:04:32.\n",
            "  Batch   640  of  11,250.    Elapsed: 0:04:50.\n",
            "  Batch   680  of  11,250.    Elapsed: 0:05:08.\n",
            "  Batch   720  of  11,250.    Elapsed: 0:05:26.\n",
            "  Batch   760  of  11,250.    Elapsed: 0:05:44.\n",
            "  Batch   800  of  11,250.    Elapsed: 0:06:02.\n",
            "  Batch   840  of  11,250.    Elapsed: 0:06:20.\n",
            "  Batch   880  of  11,250.    Elapsed: 0:06:38.\n",
            "  Batch   920  of  11,250.    Elapsed: 0:06:56.\n",
            "  Batch   960  of  11,250.    Elapsed: 0:07:14.\n",
            "  Batch 1,000  of  11,250.    Elapsed: 0:07:32.\n",
            "  Batch 1,040  of  11,250.    Elapsed: 0:07:50.\n",
            "  Batch 1,080  of  11,250.    Elapsed: 0:08:08.\n",
            "  Batch 1,120  of  11,250.    Elapsed: 0:08:27.\n",
            "  Batch 1,160  of  11,250.    Elapsed: 0:08:45.\n",
            "  Batch 1,200  of  11,250.    Elapsed: 0:09:03.\n",
            "  Batch 1,240  of  11,250.    Elapsed: 0:09:21.\n",
            "  Batch 1,280  of  11,250.    Elapsed: 0:09:39.\n",
            "  Batch 1,320  of  11,250.    Elapsed: 0:09:57.\n",
            "  Batch 1,360  of  11,250.    Elapsed: 0:10:15.\n",
            "  Batch 1,400  of  11,250.    Elapsed: 0:10:33.\n",
            "  Batch 1,440  of  11,250.    Elapsed: 0:10:51.\n",
            "  Batch 1,480  of  11,250.    Elapsed: 0:11:09.\n",
            "  Batch 1,520  of  11,250.    Elapsed: 0:11:27.\n",
            "  Batch 1,560  of  11,250.    Elapsed: 0:11:45.\n",
            "  Batch 1,600  of  11,250.    Elapsed: 0:12:03.\n",
            "  Batch 1,640  of  11,250.    Elapsed: 0:12:21.\n",
            "  Batch 1,680  of  11,250.    Elapsed: 0:12:39.\n",
            "  Batch 1,720  of  11,250.    Elapsed: 0:12:57.\n",
            "  Batch 1,760  of  11,250.    Elapsed: 0:13:15.\n",
            "  Batch 1,800  of  11,250.    Elapsed: 0:13:33.\n",
            "  Batch 1,840  of  11,250.    Elapsed: 0:13:52.\n",
            "  Batch 1,880  of  11,250.    Elapsed: 0:14:10.\n",
            "  Batch 1,920  of  11,250.    Elapsed: 0:14:28.\n",
            "  Batch 1,960  of  11,250.    Elapsed: 0:14:46.\n",
            "  Batch 2,000  of  11,250.    Elapsed: 0:15:04.\n",
            "  Batch 2,040  of  11,250.    Elapsed: 0:15:22.\n",
            "  Batch 2,080  of  11,250.    Elapsed: 0:15:40.\n",
            "  Batch 2,120  of  11,250.    Elapsed: 0:15:58.\n",
            "  Batch 2,160  of  11,250.    Elapsed: 0:16:16.\n",
            "  Batch 2,200  of  11,250.    Elapsed: 0:16:34.\n",
            "  Batch 2,240  of  11,250.    Elapsed: 0:16:52.\n",
            "  Batch 2,280  of  11,250.    Elapsed: 0:17:10.\n",
            "  Batch 2,320  of  11,250.    Elapsed: 0:17:28.\n",
            "  Batch 2,360  of  11,250.    Elapsed: 0:17:46.\n",
            "  Batch 2,400  of  11,250.    Elapsed: 0:18:04.\n",
            "  Batch 2,440  of  11,250.    Elapsed: 0:18:22.\n",
            "  Batch 2,480  of  11,250.    Elapsed: 0:18:41.\n",
            "  Batch 2,520  of  11,250.    Elapsed: 0:18:59.\n",
            "  Batch 2,560  of  11,250.    Elapsed: 0:19:17.\n",
            "  Batch 2,600  of  11,250.    Elapsed: 0:19:35.\n",
            "  Batch 2,640  of  11,250.    Elapsed: 0:19:53.\n",
            "  Batch 2,680  of  11,250.    Elapsed: 0:20:11.\n",
            "  Batch 2,720  of  11,250.    Elapsed: 0:20:29.\n",
            "  Batch 2,760  of  11,250.    Elapsed: 0:20:47.\n",
            "  Batch 2,800  of  11,250.    Elapsed: 0:21:05.\n",
            "  Batch 2,840  of  11,250.    Elapsed: 0:21:23.\n",
            "  Batch 2,880  of  11,250.    Elapsed: 0:21:41.\n",
            "  Batch 2,920  of  11,250.    Elapsed: 0:21:59.\n",
            "  Batch 2,960  of  11,250.    Elapsed: 0:22:17.\n",
            "  Batch 3,000  of  11,250.    Elapsed: 0:22:35.\n",
            "  Batch 3,040  of  11,250.    Elapsed: 0:22:53.\n",
            "  Batch 3,080  of  11,250.    Elapsed: 0:23:11.\n",
            "  Batch 3,120  of  11,250.    Elapsed: 0:23:29.\n",
            "  Batch 3,160  of  11,250.    Elapsed: 0:23:48.\n",
            "  Batch 3,200  of  11,250.    Elapsed: 0:24:06.\n",
            "  Batch 3,240  of  11,250.    Elapsed: 0:24:24.\n",
            "  Batch 3,280  of  11,250.    Elapsed: 0:24:42.\n",
            "  Batch 3,320  of  11,250.    Elapsed: 0:25:00.\n",
            "  Batch 3,360  of  11,250.    Elapsed: 0:25:18.\n",
            "  Batch 3,400  of  11,250.    Elapsed: 0:25:36.\n",
            "  Batch 3,440  of  11,250.    Elapsed: 0:25:54.\n",
            "  Batch 3,480  of  11,250.    Elapsed: 0:26:12.\n",
            "  Batch 3,520  of  11,250.    Elapsed: 0:26:30.\n",
            "  Batch 3,560  of  11,250.    Elapsed: 0:26:48.\n",
            "  Batch 3,600  of  11,250.    Elapsed: 0:27:06.\n",
            "  Batch 3,640  of  11,250.    Elapsed: 0:27:24.\n",
            "  Batch 3,680  of  11,250.    Elapsed: 0:27:42.\n",
            "  Batch 3,720  of  11,250.    Elapsed: 0:28:00.\n",
            "  Batch 3,760  of  11,250.    Elapsed: 0:28:18.\n",
            "  Batch 3,800  of  11,250.    Elapsed: 0:28:36.\n",
            "  Batch 3,840  of  11,250.    Elapsed: 0:28:54.\n",
            "  Batch 3,880  of  11,250.    Elapsed: 0:29:13.\n",
            "  Batch 3,920  of  11,250.    Elapsed: 0:29:31.\n",
            "  Batch 3,960  of  11,250.    Elapsed: 0:29:49.\n",
            "  Batch 4,000  of  11,250.    Elapsed: 0:30:07.\n",
            "  Batch 4,040  of  11,250.    Elapsed: 0:30:25.\n",
            "  Batch 4,080  of  11,250.    Elapsed: 0:30:43.\n",
            "  Batch 4,120  of  11,250.    Elapsed: 0:31:01.\n",
            "  Batch 4,160  of  11,250.    Elapsed: 0:31:19.\n",
            "  Batch 4,200  of  11,250.    Elapsed: 0:31:37.\n",
            "  Batch 4,240  of  11,250.    Elapsed: 0:31:55.\n",
            "  Batch 4,280  of  11,250.    Elapsed: 0:32:13.\n",
            "  Batch 4,320  of  11,250.    Elapsed: 0:32:31.\n",
            "  Batch 4,360  of  11,250.    Elapsed: 0:32:49.\n",
            "  Batch 4,400  of  11,250.    Elapsed: 0:33:07.\n",
            "  Batch 4,440  of  11,250.    Elapsed: 0:33:25.\n",
            "  Batch 4,480  of  11,250.    Elapsed: 0:33:43.\n",
            "  Batch 4,520  of  11,250.    Elapsed: 0:34:01.\n",
            "  Batch 4,560  of  11,250.    Elapsed: 0:34:19.\n",
            "  Batch 4,600  of  11,250.    Elapsed: 0:34:37.\n",
            "  Batch 4,640  of  11,250.    Elapsed: 0:34:56.\n",
            "  Batch 4,680  of  11,250.    Elapsed: 0:35:14.\n",
            "  Batch 4,720  of  11,250.    Elapsed: 0:35:32.\n",
            "  Batch 4,760  of  11,250.    Elapsed: 0:35:50.\n",
            "  Batch 4,800  of  11,250.    Elapsed: 0:36:08.\n",
            "  Batch 4,840  of  11,250.    Elapsed: 0:36:26.\n",
            "  Batch 4,880  of  11,250.    Elapsed: 0:36:44.\n",
            "  Batch 4,920  of  11,250.    Elapsed: 0:37:02.\n",
            "  Batch 4,960  of  11,250.    Elapsed: 0:37:20.\n",
            "  Batch 5,000  of  11,250.    Elapsed: 0:37:38.\n",
            "  Batch 5,040  of  11,250.    Elapsed: 0:37:56.\n",
            "  Batch 5,080  of  11,250.    Elapsed: 0:38:14.\n",
            "  Batch 5,120  of  11,250.    Elapsed: 0:38:32.\n",
            "  Batch 5,160  of  11,250.    Elapsed: 0:38:50.\n",
            "  Batch 5,200  of  11,250.    Elapsed: 0:39:08.\n",
            "  Batch 5,240  of  11,250.    Elapsed: 0:39:26.\n",
            "  Batch 5,280  of  11,250.    Elapsed: 0:39:44.\n",
            "  Batch 5,320  of  11,250.    Elapsed: 0:40:02.\n",
            "  Batch 5,360  of  11,250.    Elapsed: 0:40:21.\n",
            "  Batch 5,400  of  11,250.    Elapsed: 0:40:39.\n",
            "  Batch 5,440  of  11,250.    Elapsed: 0:40:57.\n",
            "  Batch 5,480  of  11,250.    Elapsed: 0:41:15.\n",
            "  Batch 5,520  of  11,250.    Elapsed: 0:41:33.\n",
            "  Batch 5,560  of  11,250.    Elapsed: 0:41:51.\n",
            "  Batch 5,600  of  11,250.    Elapsed: 0:42:09.\n",
            "  Batch 5,640  of  11,250.    Elapsed: 0:42:27.\n",
            "  Batch 5,680  of  11,250.    Elapsed: 0:42:45.\n",
            "  Batch 5,720  of  11,250.    Elapsed: 0:43:03.\n",
            "  Batch 5,760  of  11,250.    Elapsed: 0:43:21.\n",
            "  Batch 5,800  of  11,250.    Elapsed: 0:43:39.\n",
            "  Batch 5,840  of  11,250.    Elapsed: 0:43:57.\n",
            "  Batch 5,880  of  11,250.    Elapsed: 0:44:15.\n",
            "  Batch 5,920  of  11,250.    Elapsed: 0:44:33.\n",
            "  Batch 5,960  of  11,250.    Elapsed: 0:44:51.\n",
            "  Batch 6,000  of  11,250.    Elapsed: 0:45:09.\n",
            "  Batch 6,040  of  11,250.    Elapsed: 0:45:27.\n",
            "  Batch 6,080  of  11,250.    Elapsed: 0:45:45.\n",
            "  Batch 6,120  of  11,250.    Elapsed: 0:46:03.\n",
            "  Batch 6,160  of  11,250.    Elapsed: 0:46:22.\n",
            "  Batch 6,200  of  11,250.    Elapsed: 0:46:40.\n",
            "  Batch 6,240  of  11,250.    Elapsed: 0:46:58.\n",
            "  Batch 6,280  of  11,250.    Elapsed: 0:47:16.\n",
            "  Batch 6,320  of  11,250.    Elapsed: 0:47:34.\n",
            "  Batch 6,360  of  11,250.    Elapsed: 0:47:52.\n",
            "  Batch 6,400  of  11,250.    Elapsed: 0:48:10.\n",
            "  Batch 6,440  of  11,250.    Elapsed: 0:48:28.\n",
            "  Batch 6,480  of  11,250.    Elapsed: 0:48:46.\n",
            "  Batch 6,520  of  11,250.    Elapsed: 0:49:04.\n",
            "  Batch 6,560  of  11,250.    Elapsed: 0:49:22.\n",
            "  Batch 6,600  of  11,250.    Elapsed: 0:49:40.\n",
            "  Batch 6,640  of  11,250.    Elapsed: 0:49:58.\n",
            "  Batch 6,680  of  11,250.    Elapsed: 0:50:16.\n",
            "  Batch 6,720  of  11,250.    Elapsed: 0:50:34.\n",
            "  Batch 6,760  of  11,250.    Elapsed: 0:50:52.\n",
            "  Batch 6,800  of  11,250.    Elapsed: 0:51:10.\n",
            "  Batch 6,840  of  11,250.    Elapsed: 0:51:28.\n",
            "  Batch 6,880  of  11,250.    Elapsed: 0:51:47.\n",
            "  Batch 6,920  of  11,250.    Elapsed: 0:52:05.\n",
            "  Batch 6,960  of  11,250.    Elapsed: 0:52:23.\n",
            "  Batch 7,000  of  11,250.    Elapsed: 0:52:41.\n",
            "  Batch 7,040  of  11,250.    Elapsed: 0:52:59.\n",
            "  Batch 7,080  of  11,250.    Elapsed: 0:53:17.\n",
            "  Batch 7,120  of  11,250.    Elapsed: 0:53:35.\n",
            "  Batch 7,160  of  11,250.    Elapsed: 0:53:53.\n",
            "  Batch 7,200  of  11,250.    Elapsed: 0:54:11.\n",
            "  Batch 7,240  of  11,250.    Elapsed: 0:54:29.\n",
            "  Batch 7,280  of  11,250.    Elapsed: 0:54:47.\n",
            "  Batch 7,320  of  11,250.    Elapsed: 0:55:05.\n",
            "  Batch 7,360  of  11,250.    Elapsed: 0:55:23.\n",
            "  Batch 7,400  of  11,250.    Elapsed: 0:55:41.\n",
            "  Batch 7,440  of  11,250.    Elapsed: 0:55:59.\n",
            "  Batch 7,480  of  11,250.    Elapsed: 0:56:17.\n",
            "  Batch 7,520  of  11,250.    Elapsed: 0:56:35.\n",
            "  Batch 7,560  of  11,250.    Elapsed: 0:56:53.\n",
            "  Batch 7,600  of  11,250.    Elapsed: 0:57:11.\n",
            "  Batch 7,640  of  11,250.    Elapsed: 0:57:29.\n",
            "  Batch 7,680  of  11,250.    Elapsed: 0:57:48.\n",
            "  Batch 7,720  of  11,250.    Elapsed: 0:58:06.\n",
            "  Batch 7,760  of  11,250.    Elapsed: 0:58:24.\n",
            "  Batch 7,800  of  11,250.    Elapsed: 0:58:42.\n",
            "  Batch 7,840  of  11,250.    Elapsed: 0:59:00.\n",
            "  Batch 7,880  of  11,250.    Elapsed: 0:59:18.\n",
            "  Batch 7,920  of  11,250.    Elapsed: 0:59:36.\n",
            "  Batch 7,960  of  11,250.    Elapsed: 0:59:54.\n",
            "  Batch 8,000  of  11,250.    Elapsed: 1:00:12.\n",
            "  Batch 8,040  of  11,250.    Elapsed: 1:00:30.\n",
            "  Batch 8,080  of  11,250.    Elapsed: 1:00:48.\n",
            "  Batch 8,120  of  11,250.    Elapsed: 1:01:06.\n",
            "  Batch 8,160  of  11,250.    Elapsed: 1:01:24.\n",
            "  Batch 8,200  of  11,250.    Elapsed: 1:01:42.\n",
            "  Batch 8,240  of  11,250.    Elapsed: 1:02:00.\n",
            "  Batch 8,280  of  11,250.    Elapsed: 1:02:18.\n",
            "  Batch 8,320  of  11,250.    Elapsed: 1:02:36.\n",
            "  Batch 8,360  of  11,250.    Elapsed: 1:02:54.\n",
            "  Batch 8,400  of  11,250.    Elapsed: 1:03:12.\n",
            "  Batch 8,440  of  11,250.    Elapsed: 1:03:30.\n",
            "  Batch 8,480  of  11,250.    Elapsed: 1:03:49.\n",
            "  Batch 8,520  of  11,250.    Elapsed: 1:04:07.\n",
            "  Batch 8,560  of  11,250.    Elapsed: 1:04:25.\n",
            "  Batch 8,600  of  11,250.    Elapsed: 1:04:43.\n",
            "  Batch 8,640  of  11,250.    Elapsed: 1:05:01.\n",
            "  Batch 8,680  of  11,250.    Elapsed: 1:05:19.\n",
            "  Batch 8,720  of  11,250.    Elapsed: 1:05:37.\n",
            "  Batch 8,760  of  11,250.    Elapsed: 1:05:55.\n",
            "  Batch 8,800  of  11,250.    Elapsed: 1:06:13.\n",
            "  Batch 8,840  of  11,250.    Elapsed: 1:06:31.\n",
            "  Batch 8,880  of  11,250.    Elapsed: 1:06:49.\n",
            "  Batch 8,920  of  11,250.    Elapsed: 1:07:07.\n",
            "  Batch 8,960  of  11,250.    Elapsed: 1:07:25.\n",
            "  Batch 9,000  of  11,250.    Elapsed: 1:07:43.\n",
            "  Batch 9,040  of  11,250.    Elapsed: 1:08:01.\n",
            "  Batch 9,080  of  11,250.    Elapsed: 1:08:19.\n",
            "  Batch 9,120  of  11,250.    Elapsed: 1:08:37.\n",
            "  Batch 9,160  of  11,250.    Elapsed: 1:08:55.\n",
            "  Batch 9,200  of  11,250.    Elapsed: 1:09:14.\n",
            "  Batch 9,240  of  11,250.    Elapsed: 1:09:32.\n",
            "  Batch 9,280  of  11,250.    Elapsed: 1:09:50.\n",
            "  Batch 9,320  of  11,250.    Elapsed: 1:10:08.\n",
            "  Batch 9,360  of  11,250.    Elapsed: 1:10:26.\n",
            "  Batch 9,400  of  11,250.    Elapsed: 1:10:44.\n",
            "  Batch 9,440  of  11,250.    Elapsed: 1:11:02.\n",
            "  Batch 9,480  of  11,250.    Elapsed: 1:11:20.\n",
            "  Batch 9,520  of  11,250.    Elapsed: 1:11:38.\n",
            "  Batch 9,560  of  11,250.    Elapsed: 1:11:56.\n",
            "  Batch 9,600  of  11,250.    Elapsed: 1:12:14.\n",
            "  Batch 9,640  of  11,250.    Elapsed: 1:12:32.\n",
            "  Batch 9,680  of  11,250.    Elapsed: 1:12:50.\n",
            "  Batch 9,720  of  11,250.    Elapsed: 1:13:08.\n",
            "  Batch 9,760  of  11,250.    Elapsed: 1:13:26.\n",
            "  Batch 9,800  of  11,250.    Elapsed: 1:13:44.\n",
            "  Batch 9,840  of  11,250.    Elapsed: 1:14:02.\n",
            "  Batch 9,880  of  11,250.    Elapsed: 1:14:20.\n",
            "  Batch 9,920  of  11,250.    Elapsed: 1:14:38.\n",
            "  Batch 9,960  of  11,250.    Elapsed: 1:14:56.\n",
            "  Batch 10,000  of  11,250.    Elapsed: 1:15:14.\n",
            "  Batch 10,040  of  11,250.    Elapsed: 1:15:33.\n",
            "  Batch 10,080  of  11,250.    Elapsed: 1:15:51.\n",
            "  Batch 10,120  of  11,250.    Elapsed: 1:16:09.\n",
            "  Batch 10,160  of  11,250.    Elapsed: 1:16:27.\n",
            "  Batch 10,200  of  11,250.    Elapsed: 1:16:45.\n",
            "  Batch 10,240  of  11,250.    Elapsed: 1:17:03.\n",
            "  Batch 10,280  of  11,250.    Elapsed: 1:17:21.\n",
            "  Batch 10,320  of  11,250.    Elapsed: 1:17:39.\n",
            "  Batch 10,360  of  11,250.    Elapsed: 1:17:57.\n",
            "  Batch 10,400  of  11,250.    Elapsed: 1:18:15.\n",
            "  Batch 10,440  of  11,250.    Elapsed: 1:18:33.\n",
            "  Batch 10,480  of  11,250.    Elapsed: 1:18:51.\n",
            "  Batch 10,520  of  11,250.    Elapsed: 1:19:09.\n",
            "  Batch 10,560  of  11,250.    Elapsed: 1:19:27.\n",
            "  Batch 10,600  of  11,250.    Elapsed: 1:19:45.\n",
            "  Batch 10,640  of  11,250.    Elapsed: 1:20:03.\n",
            "  Batch 10,680  of  11,250.    Elapsed: 1:20:21.\n",
            "  Batch 10,720  of  11,250.    Elapsed: 1:20:39.\n",
            "  Batch 10,760  of  11,250.    Elapsed: 1:20:57.\n",
            "  Batch 10,800  of  11,250.    Elapsed: 1:21:15.\n",
            "  Batch 10,840  of  11,250.    Elapsed: 1:21:33.\n",
            "  Batch 10,880  of  11,250.    Elapsed: 1:21:51.\n",
            "  Batch 10,920  of  11,250.    Elapsed: 1:22:09.\n",
            "  Batch 10,960  of  11,250.    Elapsed: 1:22:27.\n",
            "  Batch 11,000  of  11,250.    Elapsed: 1:22:45.\n",
            "  Batch 11,040  of  11,250.    Elapsed: 1:23:03.\n",
            "  Batch 11,080  of  11,250.    Elapsed: 1:23:21.\n",
            "  Batch 11,120  of  11,250.    Elapsed: 1:23:39.\n",
            "  Batch 11,160  of  11,250.    Elapsed: 1:23:58.\n",
            "  Batch 11,200  of  11,250.    Elapsed: 1:24:16.\n",
            "  Batch 11,240  of  11,250.    Elapsed: 1:24:34.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 1:24:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.09\n",
            "  Validation took: 0:03:04\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:27:43 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "ElrUwF1UcB_W",
        "outputId": "a3716954-7400-4c5f-ba2c-3152f89c022c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.12</td>\n",
              "      <td>tensor(0.0867, device='cuda:0')</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1:24:38</td>\n",
              "      <td>0:03:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  ... Validation Time\n",
              "epoch                 ...                \n",
              "1               0.12  ...         0:03:04\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsWpsHgmJr5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "ede55ce4-8f69-4aa6-d23d-caec7a16a84e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVFTY3sKJs6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b3678d-c4b8-4ec4-febb-9aa4e48b095f"
      },
      "source": [
        "#Save weights of created model to \"output_dir\"\n",
        "import os\n",
        "\n",
        "output_dir = 'FINE2'\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model,'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('FINE2/tokenizer_config.json',\n",
              " 'FINE2/special_tokens_map.json',\n",
              " 'FINE2/vocab.txt',\n",
              " 'FINE2/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}