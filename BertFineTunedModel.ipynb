{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertFineTunedModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "457ab152be9e4ecc8a96916490e1261a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edf77d3d4eae40b2a89ec2d2ee134c68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6eec0116a4fb4c98bb1730a5f8500928",
              "IPY_MODEL_7c2a76c15b6b43aa9b838e143a356719"
            ]
          }
        },
        "edf77d3d4eae40b2a89ec2d2ee134c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6eec0116a4fb4c98bb1730a5f8500928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8bc4d17d80b48a5b5f465c6383e8cc9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_803a783330f84062ab5a2ea2214269d9"
          }
        },
        "7c2a76c15b6b43aa9b838e143a356719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa3627292e7d405297ea8ba71e8475c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:05&lt;00:00, 43.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e42a635bf3c4d5c9b2b86c0f24afec6"
          }
        },
        "c8bc4d17d80b48a5b5f465c6383e8cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "803a783330f84062ab5a2ea2214269d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa3627292e7d405297ea8ba71e8475c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e42a635bf3c4d5c9b2b86c0f24afec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60de0b6515694e1a924a69b4a3d9412b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_783c61dc10704d6d86345057185740a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7be9925a59e04bb9ba10e0792b338751",
              "IPY_MODEL_f79ed89365a44f9197fb0134b925a95a"
            ]
          }
        },
        "783c61dc10704d6d86345057185740a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7be9925a59e04bb9ba10e0792b338751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8948bfb556c480bbf9dfab1f4358af9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0aa810316d645ff978a75b528714429"
          }
        },
        "f79ed89365a44f9197fb0134b925a95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e46f5089d42446eba9f24deadd9d6965",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:02&lt;00:00, 13.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4da46a84b3b9445cb627f1311167c685"
          }
        },
        "d8948bfb556c480bbf9dfab1f4358af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0aa810316d645ff978a75b528714429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e46f5089d42446eba9f24deadd9d6965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4da46a84b3b9445cb627f1311167c685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4b3fd52498c44c389483b59314488c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8eb04d018f4240cfa3a2fb12e83a0a98",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29b068f973514afe9a415404db6e0a06",
              "IPY_MODEL_650c554eb3884f938fcc47013a32cb2a"
            ]
          }
        },
        "8eb04d018f4240cfa3a2fb12e83a0a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29b068f973514afe9a415404db6e0a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d7c566bdd154cf4ba39437bdefc6428",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efbfae12c52c40769d179784306d2901"
          }
        },
        "650c554eb3884f938fcc47013a32cb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1f08937e79c4deeadf438c0b93c01a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 497kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cebab1da2f7d444a8d8c05ff688792a0"
          }
        },
        "0d7c566bdd154cf4ba39437bdefc6428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efbfae12c52c40769d179784306d2901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1f08937e79c4deeadf438c0b93c01a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cebab1da2f7d444a8d8c05ff688792a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5e34253e25941cc89ed0c6d0d6ea005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdc66a83f84b45288de9d2a02206ff7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8750ee4ef854419c83c63c589af1ae47",
              "IPY_MODEL_98232254b17a4db691c18ddae80e5c4e"
            ]
          }
        },
        "cdc66a83f84b45288de9d2a02206ff7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8750ee4ef854419c83c63c589af1ae47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c1852d72ea84acdad7e02efd5a19e7f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7efad6a9421f44fb9ff5983c1d28f635"
          }
        },
        "98232254b17a4db691c18ddae80e5c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66beb887dbf64022ba387481fd707b08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.13kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_905f6adafd9345b08d3988cedd2344fa"
          }
        },
        "1c1852d72ea84acdad7e02efd5a19e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7efad6a9421f44fb9ff5983c1d28f635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66beb887dbf64022ba387481fd707b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "905f6adafd9345b08d3988cedd2344fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6935b7620f94ba4a2fd6b284be3b0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24dbd597f96e477e9c2e7eba60004612",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6bd6e9d95884285838f250952be8de1",
              "IPY_MODEL_929a7a09fcae4d669a0d89024cd01597"
            ]
          }
        },
        "24dbd597f96e477e9c2e7eba60004612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6bd6e9d95884285838f250952be8de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cce848e655c14052a1b1a5051dda564a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87bf8c79ea5c4d90ae31ed0b413ba668"
          }
        },
        "929a7a09fcae4d669a0d89024cd01597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f97dd7bcad0b48f884651aea672c9619",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [10:03&lt;00:00, 730kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f0b6a378d33447aab281878acfaca75"
          }
        },
        "cce848e655c14052a1b1a5051dda564a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87bf8c79ea5c4d90ae31ed0b413ba668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f97dd7bcad0b48f884651aea672c9619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f0b6a378d33447aab281878acfaca75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N1924tCz4F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b98f9c7-83e3-49aa-bc3f-ea0d3a505de3"
      },
      "source": [
        "#Import GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 17 15:08:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O74pA0j1d1Cp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725eb09f-39f1-4522-da5c-96e2fa63e17e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# Get the GPU device name.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1zSSDg8r5M0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b852ca-851b-4a2f-93dd-5e306625d35c"
      },
      "source": [
        "!pip install transformers\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import multiprocessing as mp\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=365f718eb3e768af9bc147dde8b15cf59ca2a8f06f9dc79d549d27388ee6e8dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDf44mK4sPpu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "457ab152be9e4ecc8a96916490e1261a",
            "edf77d3d4eae40b2a89ec2d2ee134c68",
            "6eec0116a4fb4c98bb1730a5f8500928",
            "7c2a76c15b6b43aa9b838e143a356719",
            "c8bc4d17d80b48a5b5f465c6383e8cc9",
            "803a783330f84062ab5a2ea2214269d9",
            "fa3627292e7d405297ea8ba71e8475c4",
            "1e42a635bf3c4d5c9b2b86c0f24afec6",
            "60de0b6515694e1a924a69b4a3d9412b",
            "783c61dc10704d6d86345057185740a2",
            "7be9925a59e04bb9ba10e0792b338751",
            "f79ed89365a44f9197fb0134b925a95a",
            "d8948bfb556c480bbf9dfab1f4358af9",
            "d0aa810316d645ff978a75b528714429",
            "e46f5089d42446eba9f24deadd9d6965",
            "4da46a84b3b9445cb627f1311167c685",
            "e4b3fd52498c44c389483b59314488c9",
            "8eb04d018f4240cfa3a2fb12e83a0a98",
            "29b068f973514afe9a415404db6e0a06",
            "650c554eb3884f938fcc47013a32cb2a",
            "0d7c566bdd154cf4ba39437bdefc6428",
            "efbfae12c52c40769d179784306d2901",
            "a1f08937e79c4deeadf438c0b93c01a9",
            "cebab1da2f7d444a8d8c05ff688792a0"
          ]
        },
        "outputId": "6acdafb4-ac2a-497c-8a56-1e31eb0a428c"
      },
      "source": [
        "#TOKENIZE TEXT\n",
        "flatten = lambda t: [item for sublist in t for item in sublist]\n",
        "\n",
        "tok = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "print(MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "457ab152be9e4ecc8a96916490e1261a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60de0b6515694e1a924a69b4a3d9412b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4b3fd52498c44c389483b59314488c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1PUhmkCsc8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d90ed2-52b8-42ec-f0da-863e061564b0"
      },
      "source": [
        "#tokenize\n",
        "def tokenize(x):\n",
        "    return tok.encode(x)[1:-1]\n",
        "print(\"Data: tokenized\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: tokenized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZYMYQ81shA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad58028-8d60-42a2-87ad-78cb4db0bef1"
      },
      "source": [
        "#masking & batching\n",
        "def process(_n):\n",
        "    n = _n\n",
        "    size = math.ceil(len(n)*0.15)\n",
        "    indices = random.sample(range(len(n)), size)\n",
        "    replacement_prob = [True, True, True, True, True, True, True, True, False, False]\n",
        "    output = [-100]*len(n)\n",
        "    for index in indices:\n",
        "        output[index] = n[index]\n",
        "        if random.choice(replacement_prob):\n",
        "            n[index] = 103\n",
        "        else:\n",
        "            if random.choice([True, False]):\n",
        "                n[index] = random.randint(1010, 30500)\n",
        "    return (n, output)\n",
        "\n",
        "def batcher(ins, outs):\n",
        "    batchx, batchy, batchesx, batchesy, batchesmasks = [], [], [], [], []\n",
        "    for i in zip(ins, outs):\n",
        "        batchx.append(i[0])\n",
        "        batchy.append(i[1])\n",
        "        if len(batchx) == BATCH_SIZE:\n",
        "            maxlen = max([len(x) for x in batchx])\n",
        "            masks = [[1] * len(x) + [0] * (maxlen - len(x)) for x in batchx]\n",
        "            batchx = [x + [0] * (maxlen - len(x)) for x in batchx]\n",
        "            batchy = [x + [0] * (maxlen - len(x)) for x in batchy]\n",
        "            batchesx.append(batchx)\n",
        "            batchesy.append(batchy)\n",
        "            batchesmasks.append(masks)\n",
        "            batchx = []\n",
        "            batchy = []\n",
        "    return [batchesx, batchesy, batchesmasks]\n",
        "print(\"Data: masked & batched\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: masked & batched\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4M7xjeKtDBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "cfb20499-9d23-48c6-d2ea-6be2f20d29a3"
      },
      "source": [
        "#save to disk\n",
        "real_data = list(set(flatten([x.split(\".\") for x in open(\"data_post_training20k\").read().split(\".\")])))\n",
        "print(len(real_data))\n",
        "random.shuffle(real_data)\n",
        "\n",
        "pool = mp.Pool()\n",
        "tokenized = list(tqdm(pool.imap(tokenize, real_data), total=len(real_data)))\n",
        "\n",
        "inputs = tokenized\n",
        "outputs = list(tqdm(pool.imap(process, tokenized), total=len(tokenized)))\n",
        "outputs.sort(key=lambda x: len(x[0]))\n",
        "\n",
        "inputs = [[101] + x[0] + [102] for x in outputs]\n",
        "outputs = [[-100] + x[1] + [-100] for x in outputs]\n",
        "\n",
        "batched = batcher(inputs, outputs)\n",
        "pickle.dump(batched, open(\"lblq_data.pkl\", \"wb\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1efe7d5fc2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#save to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_post_training20k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_post_training20k'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21ouofbZwtO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1055c91-a5c1-4cd8-8f75-a603158a7323"
      },
      "source": [
        "#training\n",
        "!pip install transformers\n",
        "!pip install pytorch-lightning\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "device = torch.device(dev)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from transformers import BertForMaskedLM\n",
        "print(\"done installing and importing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/99/68da5c6ca999de560036d98c492e507d17996f5eeb7e76ba64acd4bbb142/pytorch_lightning-1.2.8-py3-none-any.whl (841kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n",
            "Collecting PyYAML!=5.4.*,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 41.0MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/42/d984612cabf005a265aa99c8d4ab2958e37b753aafb12f31c81df38751c8/torchmetrics-0.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 42.1MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/11/f7689b996f85e45f718745c899f6747ee5edb4878cadac0a41ab146828fa/fsspec-0.9.0-py3-none-any.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (54.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.10.0)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.4.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 28.9MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Building wheels for collected packages: future, PyYAML\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=029e0badcd29b07e2ced4cd7248a9e8d4be3425c3febcb2d980b8acb860bb3ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=65cab33e90228caa384d3cb40a3245ff2fbf1fa9725843537e1271f6a97b1a12\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built future PyYAML\n",
            "Installing collected packages: future, PyYAML, torchmetrics, multidict, yarl, async-timeout, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-0.9.0 future-0.18.2 multidict-5.1.0 pytorch-lightning-1.2.8 torchmetrics-0.2.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n",
            "done installing and importing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-ozHV7zx8Rn"
      },
      "source": [
        "class PTDataset(Dataset):\n",
        "  #loading data\n",
        "    def __init__(self):\n",
        "        self.data = pickle.load(open(\"lblq_data.pkl\", \"rb\"))\n",
        "        idxs = list(range(len(self.data[0])))\n",
        "        random.shuffle(idxs)\n",
        "        self.data = [[x[i] for i in idxs] for x in self.data]\n",
        "        print(\"Loaded {} rows of data\".format(len(self.data[0])))\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [torch.tensor(x[idx]) for x in self.data]\n",
        "print(\"check\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHIu-Th1ywIf"
      },
      "source": [
        "class BertRestPT(pl.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #open bert model \n",
        "        self.bert = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "#feed masks and data\n",
        "    def forward(self, x):\n",
        "        inp, out, mask = x\n",
        "        enc = self.bert(input_ids=inp, attention_mask=mask, labels=out)\n",
        "        return enc\n",
        "#running training steps\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        yhat = self(batch)\n",
        "        loss = yhat.loss\n",
        "        return {'loss': loss}\n",
        "#uses Adam optimizer for loss\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=5e-5, eps=1e-4)\n",
        "print(\"check\")\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_T--KraJo1z"
      },
      "source": [
        "#Save post-trained data\n",
        "if __name__ == \"__main__\":\n",
        "    trainer = pl.Trainer(gpus=1, distributed_backend='ddp', max_epochs=4)\n",
        "    dataset = PTDataset()\n",
        "    dataloader = DataLoader(dataset,batch_size = None)\n",
        "\n",
        "    print(\"Loading model\")\n",
        "    model = BertRestPT()\n",
        "    print(\"Loaded model\")\n",
        "    trainer.fit(model, dataloader)\n",
        "    model.bert.save_pretrained(\"POST2\")\n",
        "print(\"bert model save\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmqWX1VEOAkX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e5e34253e25941cc89ed0c6d0d6ea005",
            "cdc66a83f84b45288de9d2a02206ff7b",
            "8750ee4ef854419c83c63c589af1ae47",
            "98232254b17a4db691c18ddae80e5c4e",
            "1c1852d72ea84acdad7e02efd5a19e7f",
            "7efad6a9421f44fb9ff5983c1d28f635",
            "66beb887dbf64022ba387481fd707b08",
            "905f6adafd9345b08d3988cedd2344fa",
            "c6935b7620f94ba4a2fd6b284be3b0a0",
            "24dbd597f96e477e9c2e7eba60004612",
            "c6bd6e9d95884285838f250952be8de1",
            "929a7a09fcae4d669a0d89024cd01597",
            "cce848e655c14052a1b1a5051dda564a",
            "87bf8c79ea5c4d90ae31ed0b413ba668",
            "f97dd7bcad0b48f884651aea672c9619",
            "8f0b6a378d33447aab281878acfaca75"
          ]
        },
        "outputId": "60cc6b82-b900-4a0d-f7e5-59ea6d8a76b0"
      },
      "source": [
        "#Model is post-trained on domain-specific corpus,\n",
        "#Start fine-tuning bert by import the task you want to fine-tune BERT on\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load Post-Trained BERT model, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', # Use the post-trained domain specific BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5e34253e25941cc89ed0c6d0d6ea005",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6935b7620f94ba4a2fd6b284be3b0a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSbvX037ZoKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8300cb1e-bdec-43a5-9b7e-56e59037d2a0"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSKk9vYdadov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8883d15-1253-46a6-9724-8e38b1ba712b"
      },
      "source": [
        "#Input for training is expected as : *rating*,/,*sentence*,|,\n",
        "print('Loading restaurant review data...')\n",
        "file = open('/content/restData19', 'r')\n",
        "review = file.read()\n",
        "review = review.replace(\"\\n\\n\", ' ')\n",
        "reviews = review.split(\",|,\")\n",
        "sentences = []\n",
        "labels = []\n",
        "i = 0 \n",
        "for rev in reviews:\n",
        "  sen = rev.split(\",/,\")\n",
        "  sentences.append(sen[1])\n",
        "  labels.append(int(sen[0]))\n",
        "  i += 1\n",
        "file = open('/content/restData12', 'r')\n",
        "review1 = file.read()\n",
        "review1 = review1.replace(\"\\n\\n\", ' ')\n",
        "reviews2 = review1.split(\",|,\")\n",
        "i = 0 \n",
        "for rev in reviews2:\n",
        "  sen = rev.split(\",/,\")\n",
        "  sentences.append(sen[1])\n",
        "  labels.append(int(sen[0]))\n",
        "  i += 1\n",
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading restaurant review data...\n",
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz1urTK_t2_H",
        "outputId": "6881c66d-c183-49c8-a4d0-5d055b393cb4"
      },
      "source": [
        "#CODE TO READING ONLY 1 FILE TO CREATE WORD EMBEDDINGS\n",
        "print('Loading restaurant review data...')\n",
        "file = open('/content/restDataTrial.txt', 'r')\n",
        "review = file.read()\n",
        "review = review.replace(\"\\n\\n\", ' ')\n",
        "reviews = review.split(\",|,\")\n",
        "sentences = []\n",
        "labels = []\n",
        "i = 0 \n",
        "for rev in reviews:\n",
        "  sen = rev.split(\",/,\")\n",
        "  sentences.append(sen[1])\n",
        "  labels.append(int(sen[0]))\n",
        "  i += 1\n",
        "file.close()\n",
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading restaurant review data...\n",
            "34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo_TvYF1ZuI-"
      },
      "source": [
        "#Call optimizer that we want to use for training\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDBXtYAxaLAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96ecbaa-8c3a-4fdc-8978-78062fcdb94c"
      },
      "source": [
        "import time\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lfIodngaGM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9acea5f-eb7c-4f1a-a22d-64b2f239d63e"
      },
      "source": [
        "import torch\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "start = time.time()\n",
        "labels = torch.tensor(labels)\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation = True,\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(\"Tijd: \", end-start, \"s\")\n",
        "print(str(len(input_ids)) + ' reviews are now tokenized and have appropriate format en length.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tijd:  256.449090719223 s\n",
            "100000 reviews are now tokenized and have appropriate format en length.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do9LavwsaB7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673ea021-798e-4798-b1a0-32db7b82277a"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90,000 training samples\n",
            "10,000 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrxLDY_IZ9DD"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ukiu9NHZzlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5d7412-b0d8-4ebb-dd8d-35dc9fa7639d"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "print(\"check\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKChBjqVbnUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9418710-4507-4593-855e-db9b7a737d2c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "print(\"check\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmHexoufbxei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6fc3cc-e5f4-416c-abbc-3345109af0a3"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "print(\"double check\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "double check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grDvTzmqb3Rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc88e388-2119-43a6-b8d0-cc3aebc583aa"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "device = torch.device(dev)\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += outputs.loss\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  11,250.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  11,250.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  11,250.    Elapsed: 0:00:31.\n",
            "  Batch   160  of  11,250.    Elapsed: 0:00:41.\n",
            "  Batch   200  of  11,250.    Elapsed: 0:00:52.\n",
            "  Batch   240  of  11,250.    Elapsed: 0:01:02.\n",
            "  Batch   280  of  11,250.    Elapsed: 0:01:12.\n",
            "  Batch   320  of  11,250.    Elapsed: 0:01:22.\n",
            "  Batch   360  of  11,250.    Elapsed: 0:01:33.\n",
            "  Batch   400  of  11,250.    Elapsed: 0:01:43.\n",
            "  Batch   440  of  11,250.    Elapsed: 0:01:53.\n",
            "  Batch   480  of  11,250.    Elapsed: 0:02:03.\n",
            "  Batch   520  of  11,250.    Elapsed: 0:02:14.\n",
            "  Batch   560  of  11,250.    Elapsed: 0:02:24.\n",
            "  Batch   600  of  11,250.    Elapsed: 0:02:34.\n",
            "  Batch   640  of  11,250.    Elapsed: 0:02:44.\n",
            "  Batch   680  of  11,250.    Elapsed: 0:02:55.\n",
            "  Batch   720  of  11,250.    Elapsed: 0:03:05.\n",
            "  Batch   760  of  11,250.    Elapsed: 0:03:15.\n",
            "  Batch   800  of  11,250.    Elapsed: 0:03:25.\n",
            "  Batch   840  of  11,250.    Elapsed: 0:03:36.\n",
            "  Batch   880  of  11,250.    Elapsed: 0:03:46.\n",
            "  Batch   920  of  11,250.    Elapsed: 0:03:56.\n",
            "  Batch   960  of  11,250.    Elapsed: 0:04:06.\n",
            "  Batch 1,000  of  11,250.    Elapsed: 0:04:17.\n",
            "  Batch 1,040  of  11,250.    Elapsed: 0:04:27.\n",
            "  Batch 1,080  of  11,250.    Elapsed: 0:04:37.\n",
            "  Batch 1,120  of  11,250.    Elapsed: 0:04:47.\n",
            "  Batch 1,160  of  11,250.    Elapsed: 0:04:58.\n",
            "  Batch 1,200  of  11,250.    Elapsed: 0:05:08.\n",
            "  Batch 1,240  of  11,250.    Elapsed: 0:05:18.\n",
            "  Batch 1,280  of  11,250.    Elapsed: 0:05:28.\n",
            "  Batch 1,320  of  11,250.    Elapsed: 0:05:38.\n",
            "  Batch 1,360  of  11,250.    Elapsed: 0:05:49.\n",
            "  Batch 1,400  of  11,250.    Elapsed: 0:05:59.\n",
            "  Batch 1,440  of  11,250.    Elapsed: 0:06:09.\n",
            "  Batch 1,480  of  11,250.    Elapsed: 0:06:19.\n",
            "  Batch 1,520  of  11,250.    Elapsed: 0:06:30.\n",
            "  Batch 1,560  of  11,250.    Elapsed: 0:06:40.\n",
            "  Batch 1,600  of  11,250.    Elapsed: 0:06:50.\n",
            "  Batch 1,640  of  11,250.    Elapsed: 0:07:00.\n",
            "  Batch 1,680  of  11,250.    Elapsed: 0:07:11.\n",
            "  Batch 1,720  of  11,250.    Elapsed: 0:07:21.\n",
            "  Batch 1,760  of  11,250.    Elapsed: 0:07:31.\n",
            "  Batch 1,800  of  11,250.    Elapsed: 0:07:41.\n",
            "  Batch 1,840  of  11,250.    Elapsed: 0:07:51.\n",
            "  Batch 1,880  of  11,250.    Elapsed: 0:08:02.\n",
            "  Batch 1,920  of  11,250.    Elapsed: 0:08:12.\n",
            "  Batch 1,960  of  11,250.    Elapsed: 0:08:22.\n",
            "  Batch 2,000  of  11,250.    Elapsed: 0:08:32.\n",
            "  Batch 2,040  of  11,250.    Elapsed: 0:08:43.\n",
            "  Batch 2,080  of  11,250.    Elapsed: 0:08:53.\n",
            "  Batch 2,120  of  11,250.    Elapsed: 0:09:03.\n",
            "  Batch 2,160  of  11,250.    Elapsed: 0:09:13.\n",
            "  Batch 2,200  of  11,250.    Elapsed: 0:09:24.\n",
            "  Batch 2,240  of  11,250.    Elapsed: 0:09:34.\n",
            "  Batch 2,280  of  11,250.    Elapsed: 0:09:44.\n",
            "  Batch 2,320  of  11,250.    Elapsed: 0:09:54.\n",
            "  Batch 2,360  of  11,250.    Elapsed: 0:10:04.\n",
            "  Batch 2,400  of  11,250.    Elapsed: 0:10:15.\n",
            "  Batch 2,440  of  11,250.    Elapsed: 0:10:25.\n",
            "  Batch 2,480  of  11,250.    Elapsed: 0:10:35.\n",
            "  Batch 2,520  of  11,250.    Elapsed: 0:10:45.\n",
            "  Batch 2,560  of  11,250.    Elapsed: 0:10:56.\n",
            "  Batch 2,600  of  11,250.    Elapsed: 0:11:06.\n",
            "  Batch 2,640  of  11,250.    Elapsed: 0:11:16.\n",
            "  Batch 2,680  of  11,250.    Elapsed: 0:11:26.\n",
            "  Batch 2,720  of  11,250.    Elapsed: 0:11:36.\n",
            "  Batch 2,760  of  11,250.    Elapsed: 0:11:47.\n",
            "  Batch 2,800  of  11,250.    Elapsed: 0:11:57.\n",
            "  Batch 2,840  of  11,250.    Elapsed: 0:12:07.\n",
            "  Batch 2,880  of  11,250.    Elapsed: 0:12:17.\n",
            "  Batch 2,920  of  11,250.    Elapsed: 0:12:27.\n",
            "  Batch 2,960  of  11,250.    Elapsed: 0:12:38.\n",
            "  Batch 3,000  of  11,250.    Elapsed: 0:12:48.\n",
            "  Batch 3,040  of  11,250.    Elapsed: 0:12:58.\n",
            "  Batch 3,080  of  11,250.    Elapsed: 0:13:08.\n",
            "  Batch 3,120  of  11,250.    Elapsed: 0:13:18.\n",
            "  Batch 3,160  of  11,250.    Elapsed: 0:13:29.\n",
            "  Batch 3,200  of  11,250.    Elapsed: 0:13:39.\n",
            "  Batch 3,240  of  11,250.    Elapsed: 0:13:49.\n",
            "  Batch 3,280  of  11,250.    Elapsed: 0:13:59.\n",
            "  Batch 3,320  of  11,250.    Elapsed: 0:14:10.\n",
            "  Batch 3,360  of  11,250.    Elapsed: 0:14:20.\n",
            "  Batch 3,400  of  11,250.    Elapsed: 0:14:30.\n",
            "  Batch 3,440  of  11,250.    Elapsed: 0:14:40.\n",
            "  Batch 3,480  of  11,250.    Elapsed: 0:14:50.\n",
            "  Batch 3,520  of  11,250.    Elapsed: 0:15:01.\n",
            "  Batch 3,560  of  11,250.    Elapsed: 0:15:11.\n",
            "  Batch 3,600  of  11,250.    Elapsed: 0:15:21.\n",
            "  Batch 3,640  of  11,250.    Elapsed: 0:15:31.\n",
            "  Batch 3,680  of  11,250.    Elapsed: 0:15:41.\n",
            "  Batch 3,720  of  11,250.    Elapsed: 0:15:52.\n",
            "  Batch 3,760  of  11,250.    Elapsed: 0:16:02.\n",
            "  Batch 3,800  of  11,250.    Elapsed: 0:16:12.\n",
            "  Batch 3,840  of  11,250.    Elapsed: 0:16:22.\n",
            "  Batch 3,880  of  11,250.    Elapsed: 0:16:33.\n",
            "  Batch 3,920  of  11,250.    Elapsed: 0:16:43.\n",
            "  Batch 3,960  of  11,250.    Elapsed: 0:16:53.\n",
            "  Batch 4,000  of  11,250.    Elapsed: 0:17:03.\n",
            "  Batch 4,040  of  11,250.    Elapsed: 0:17:13.\n",
            "  Batch 4,080  of  11,250.    Elapsed: 0:17:24.\n",
            "  Batch 4,120  of  11,250.    Elapsed: 0:17:34.\n",
            "  Batch 4,160  of  11,250.    Elapsed: 0:17:44.\n",
            "  Batch 4,200  of  11,250.    Elapsed: 0:17:54.\n",
            "  Batch 4,240  of  11,250.    Elapsed: 0:18:04.\n",
            "  Batch 4,280  of  11,250.    Elapsed: 0:18:15.\n",
            "  Batch 4,320  of  11,250.    Elapsed: 0:18:25.\n",
            "  Batch 4,360  of  11,250.    Elapsed: 0:18:35.\n",
            "  Batch 4,400  of  11,250.    Elapsed: 0:18:45.\n",
            "  Batch 4,440  of  11,250.    Elapsed: 0:18:55.\n",
            "  Batch 4,480  of  11,250.    Elapsed: 0:19:06.\n",
            "  Batch 4,520  of  11,250.    Elapsed: 0:19:16.\n",
            "  Batch 4,560  of  11,250.    Elapsed: 0:19:26.\n",
            "  Batch 4,600  of  11,250.    Elapsed: 0:19:36.\n",
            "  Batch 4,640  of  11,250.    Elapsed: 0:19:46.\n",
            "  Batch 4,680  of  11,250.    Elapsed: 0:19:57.\n",
            "  Batch 4,720  of  11,250.    Elapsed: 0:20:07.\n",
            "  Batch 4,760  of  11,250.    Elapsed: 0:20:17.\n",
            "  Batch 4,800  of  11,250.    Elapsed: 0:20:27.\n",
            "  Batch 4,840  of  11,250.    Elapsed: 0:20:37.\n",
            "  Batch 4,880  of  11,250.    Elapsed: 0:20:48.\n",
            "  Batch 4,920  of  11,250.    Elapsed: 0:20:58.\n",
            "  Batch 4,960  of  11,250.    Elapsed: 0:21:08.\n",
            "  Batch 5,000  of  11,250.    Elapsed: 0:21:18.\n",
            "  Batch 5,040  of  11,250.    Elapsed: 0:21:28.\n",
            "  Batch 5,080  of  11,250.    Elapsed: 0:21:39.\n",
            "  Batch 5,120  of  11,250.    Elapsed: 0:21:49.\n",
            "  Batch 5,160  of  11,250.    Elapsed: 0:21:59.\n",
            "  Batch 5,200  of  11,250.    Elapsed: 0:22:09.\n",
            "  Batch 5,240  of  11,250.    Elapsed: 0:22:19.\n",
            "  Batch 5,280  of  11,250.    Elapsed: 0:22:30.\n",
            "  Batch 5,320  of  11,250.    Elapsed: 0:22:40.\n",
            "  Batch 5,360  of  11,250.    Elapsed: 0:22:50.\n",
            "  Batch 5,400  of  11,250.    Elapsed: 0:23:00.\n",
            "  Batch 5,440  of  11,250.    Elapsed: 0:23:10.\n",
            "  Batch 5,480  of  11,250.    Elapsed: 0:23:21.\n",
            "  Batch 5,520  of  11,250.    Elapsed: 0:23:31.\n",
            "  Batch 5,560  of  11,250.    Elapsed: 0:23:41.\n",
            "  Batch 5,600  of  11,250.    Elapsed: 0:23:51.\n",
            "  Batch 5,640  of  11,250.    Elapsed: 0:24:02.\n",
            "  Batch 5,680  of  11,250.    Elapsed: 0:24:12.\n",
            "  Batch 5,720  of  11,250.    Elapsed: 0:24:22.\n",
            "  Batch 5,760  of  11,250.    Elapsed: 0:24:32.\n",
            "  Batch 5,800  of  11,250.    Elapsed: 0:24:42.\n",
            "  Batch 5,840  of  11,250.    Elapsed: 0:24:53.\n",
            "  Batch 5,880  of  11,250.    Elapsed: 0:25:03.\n",
            "  Batch 5,920  of  11,250.    Elapsed: 0:25:13.\n",
            "  Batch 5,960  of  11,250.    Elapsed: 0:25:23.\n",
            "  Batch 6,000  of  11,250.    Elapsed: 0:25:34.\n",
            "  Batch 6,040  of  11,250.    Elapsed: 0:25:44.\n",
            "  Batch 6,080  of  11,250.    Elapsed: 0:25:54.\n",
            "  Batch 6,120  of  11,250.    Elapsed: 0:26:04.\n",
            "  Batch 6,160  of  11,250.    Elapsed: 0:26:15.\n",
            "  Batch 6,200  of  11,250.    Elapsed: 0:26:25.\n",
            "  Batch 6,240  of  11,250.    Elapsed: 0:26:35.\n",
            "  Batch 6,280  of  11,250.    Elapsed: 0:26:45.\n",
            "  Batch 6,320  of  11,250.    Elapsed: 0:26:56.\n",
            "  Batch 6,360  of  11,250.    Elapsed: 0:27:06.\n",
            "  Batch 6,400  of  11,250.    Elapsed: 0:27:16.\n",
            "  Batch 6,440  of  11,250.    Elapsed: 0:27:26.\n",
            "  Batch 6,480  of  11,250.    Elapsed: 0:27:37.\n",
            "  Batch 6,520  of  11,250.    Elapsed: 0:27:47.\n",
            "  Batch 6,560  of  11,250.    Elapsed: 0:27:57.\n",
            "  Batch 6,600  of  11,250.    Elapsed: 0:28:07.\n",
            "  Batch 6,640  of  11,250.    Elapsed: 0:28:18.\n",
            "  Batch 6,680  of  11,250.    Elapsed: 0:28:28.\n",
            "  Batch 6,720  of  11,250.    Elapsed: 0:28:38.\n",
            "  Batch 6,760  of  11,250.    Elapsed: 0:28:48.\n",
            "  Batch 6,800  of  11,250.    Elapsed: 0:28:59.\n",
            "  Batch 6,840  of  11,250.    Elapsed: 0:29:09.\n",
            "  Batch 6,880  of  11,250.    Elapsed: 0:29:19.\n",
            "  Batch 6,920  of  11,250.    Elapsed: 0:29:29.\n",
            "  Batch 6,960  of  11,250.    Elapsed: 0:29:39.\n",
            "  Batch 7,000  of  11,250.    Elapsed: 0:29:50.\n",
            "  Batch 7,040  of  11,250.    Elapsed: 0:30:00.\n",
            "  Batch 7,080  of  11,250.    Elapsed: 0:30:10.\n",
            "  Batch 7,120  of  11,250.    Elapsed: 0:30:20.\n",
            "  Batch 7,160  of  11,250.    Elapsed: 0:30:31.\n",
            "  Batch 7,200  of  11,250.    Elapsed: 0:30:41.\n",
            "  Batch 7,240  of  11,250.    Elapsed: 0:30:51.\n",
            "  Batch 7,280  of  11,250.    Elapsed: 0:31:01.\n",
            "  Batch 7,320  of  11,250.    Elapsed: 0:31:11.\n",
            "  Batch 7,360  of  11,250.    Elapsed: 0:31:22.\n",
            "  Batch 7,400  of  11,250.    Elapsed: 0:31:32.\n",
            "  Batch 7,440  of  11,250.    Elapsed: 0:31:42.\n",
            "  Batch 7,480  of  11,250.    Elapsed: 0:31:52.\n",
            "  Batch 7,520  of  11,250.    Elapsed: 0:32:02.\n",
            "  Batch 7,560  of  11,250.    Elapsed: 0:32:13.\n",
            "  Batch 7,600  of  11,250.    Elapsed: 0:32:23.\n",
            "  Batch 7,640  of  11,250.    Elapsed: 0:32:33.\n",
            "  Batch 7,680  of  11,250.    Elapsed: 0:32:43.\n",
            "  Batch 7,720  of  11,250.    Elapsed: 0:32:53.\n",
            "  Batch 7,760  of  11,250.    Elapsed: 0:33:04.\n",
            "  Batch 7,800  of  11,250.    Elapsed: 0:33:14.\n",
            "  Batch 7,840  of  11,250.    Elapsed: 0:33:24.\n",
            "  Batch 7,880  of  11,250.    Elapsed: 0:33:34.\n",
            "  Batch 7,920  of  11,250.    Elapsed: 0:33:45.\n",
            "  Batch 7,960  of  11,250.    Elapsed: 0:33:55.\n",
            "  Batch 8,000  of  11,250.    Elapsed: 0:34:05.\n",
            "  Batch 8,040  of  11,250.    Elapsed: 0:34:15.\n",
            "  Batch 8,080  of  11,250.    Elapsed: 0:34:25.\n",
            "  Batch 8,120  of  11,250.    Elapsed: 0:34:36.\n",
            "  Batch 8,160  of  11,250.    Elapsed: 0:34:46.\n",
            "  Batch 8,200  of  11,250.    Elapsed: 0:34:56.\n",
            "  Batch 8,240  of  11,250.    Elapsed: 0:35:06.\n",
            "  Batch 8,280  of  11,250.    Elapsed: 0:35:16.\n",
            "  Batch 8,320  of  11,250.    Elapsed: 0:35:27.\n",
            "  Batch 8,360  of  11,250.    Elapsed: 0:35:37.\n",
            "  Batch 8,400  of  11,250.    Elapsed: 0:35:47.\n",
            "  Batch 8,440  of  11,250.    Elapsed: 0:35:57.\n",
            "  Batch 8,480  of  11,250.    Elapsed: 0:36:07.\n",
            "  Batch 8,520  of  11,250.    Elapsed: 0:36:18.\n",
            "  Batch 8,560  of  11,250.    Elapsed: 0:36:28.\n",
            "  Batch 8,600  of  11,250.    Elapsed: 0:36:38.\n",
            "  Batch 8,640  of  11,250.    Elapsed: 0:36:48.\n",
            "  Batch 8,680  of  11,250.    Elapsed: 0:36:58.\n",
            "  Batch 8,720  of  11,250.    Elapsed: 0:37:09.\n",
            "  Batch 8,760  of  11,250.    Elapsed: 0:37:19.\n",
            "  Batch 8,800  of  11,250.    Elapsed: 0:37:29.\n",
            "  Batch 8,840  of  11,250.    Elapsed: 0:37:39.\n",
            "  Batch 8,880  of  11,250.    Elapsed: 0:37:50.\n",
            "  Batch 8,920  of  11,250.    Elapsed: 0:38:00.\n",
            "  Batch 8,960  of  11,250.    Elapsed: 0:38:10.\n",
            "  Batch 9,000  of  11,250.    Elapsed: 0:38:20.\n",
            "  Batch 9,040  of  11,250.    Elapsed: 0:38:30.\n",
            "  Batch 9,080  of  11,250.    Elapsed: 0:38:41.\n",
            "  Batch 9,120  of  11,250.    Elapsed: 0:38:51.\n",
            "  Batch 9,160  of  11,250.    Elapsed: 0:39:01.\n",
            "  Batch 9,200  of  11,250.    Elapsed: 0:39:11.\n",
            "  Batch 9,240  of  11,250.    Elapsed: 0:39:21.\n",
            "  Batch 9,280  of  11,250.    Elapsed: 0:39:32.\n",
            "  Batch 9,320  of  11,250.    Elapsed: 0:39:42.\n",
            "  Batch 9,360  of  11,250.    Elapsed: 0:39:52.\n",
            "  Batch 9,400  of  11,250.    Elapsed: 0:40:02.\n",
            "  Batch 9,440  of  11,250.    Elapsed: 0:40:13.\n",
            "  Batch 9,480  of  11,250.    Elapsed: 0:40:23.\n",
            "  Batch 9,520  of  11,250.    Elapsed: 0:40:33.\n",
            "  Batch 9,560  of  11,250.    Elapsed: 0:40:43.\n",
            "  Batch 9,600  of  11,250.    Elapsed: 0:40:53.\n",
            "  Batch 9,640  of  11,250.    Elapsed: 0:41:04.\n",
            "  Batch 9,680  of  11,250.    Elapsed: 0:41:14.\n",
            "  Batch 9,720  of  11,250.    Elapsed: 0:41:24.\n",
            "  Batch 9,760  of  11,250.    Elapsed: 0:41:34.\n",
            "  Batch 9,800  of  11,250.    Elapsed: 0:41:44.\n",
            "  Batch 9,840  of  11,250.    Elapsed: 0:41:55.\n",
            "  Batch 9,880  of  11,250.    Elapsed: 0:42:05.\n",
            "  Batch 9,920  of  11,250.    Elapsed: 0:42:15.\n",
            "  Batch 9,960  of  11,250.    Elapsed: 0:42:25.\n",
            "  Batch 10,000  of  11,250.    Elapsed: 0:42:36.\n",
            "  Batch 10,040  of  11,250.    Elapsed: 0:42:46.\n",
            "  Batch 10,080  of  11,250.    Elapsed: 0:42:56.\n",
            "  Batch 10,120  of  11,250.    Elapsed: 0:43:06.\n",
            "  Batch 10,160  of  11,250.    Elapsed: 0:43:16.\n",
            "  Batch 10,200  of  11,250.    Elapsed: 0:43:27.\n",
            "  Batch 10,240  of  11,250.    Elapsed: 0:43:37.\n",
            "  Batch 10,280  of  11,250.    Elapsed: 0:43:47.\n",
            "  Batch 10,320  of  11,250.    Elapsed: 0:43:57.\n",
            "  Batch 10,360  of  11,250.    Elapsed: 0:44:07.\n",
            "  Batch 10,400  of  11,250.    Elapsed: 0:44:18.\n",
            "  Batch 10,440  of  11,250.    Elapsed: 0:44:28.\n",
            "  Batch 10,480  of  11,250.    Elapsed: 0:44:38.\n",
            "  Batch 10,520  of  11,250.    Elapsed: 0:44:48.\n",
            "  Batch 10,560  of  11,250.    Elapsed: 0:44:59.\n",
            "  Batch 10,600  of  11,250.    Elapsed: 0:45:09.\n",
            "  Batch 10,640  of  11,250.    Elapsed: 0:45:19.\n",
            "  Batch 10,680  of  11,250.    Elapsed: 0:45:29.\n",
            "  Batch 10,720  of  11,250.    Elapsed: 0:45:39.\n",
            "  Batch 10,760  of  11,250.    Elapsed: 0:45:50.\n",
            "  Batch 10,800  of  11,250.    Elapsed: 0:46:00.\n",
            "  Batch 10,840  of  11,250.    Elapsed: 0:46:10.\n",
            "  Batch 10,880  of  11,250.    Elapsed: 0:46:20.\n",
            "  Batch 10,920  of  11,250.    Elapsed: 0:46:31.\n",
            "  Batch 10,960  of  11,250.    Elapsed: 0:46:41.\n",
            "  Batch 11,000  of  11,250.    Elapsed: 0:46:51.\n",
            "  Batch 11,040  of  11,250.    Elapsed: 0:47:01.\n",
            "  Batch 11,080  of  11,250.    Elapsed: 0:47:11.\n",
            "  Batch 11,120  of  11,250.    Elapsed: 0:47:22.\n",
            "  Batch 11,160  of  11,250.    Elapsed: 0:47:32.\n",
            "  Batch 11,200  of  11,250.    Elapsed: 0:47:42.\n",
            "  Batch 11,240  of  11,250.    Elapsed: 0:47:52.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:47:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.07\n",
            "  Validation took: 0:01:39\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:49:34 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElrUwF1UcB_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "587d755d-3c8e-471f-884b-924d02ca6847"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statisics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.11</td>\n",
              "      <td>tensor(0.0744, device='cuda:0')</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0:47:55</td>\n",
              "      <td>0:01:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  ... Validation Time\n",
              "epoch                 ...                \n",
              "1               0.11  ...         0:01:39\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsWpsHgmJr5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "eb2dd4ee-fd6d-46aa-8f86-90c2e46bb630"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVFTY3sKJs6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb6f9ae-98f9-470b-e85e-f62fd81c56df"
      },
      "source": [
        "#Save weights of created model to \"output_dir\"\n",
        "import os\n",
        "\n",
        "output_dir = 'Fine_Tuned_No_Post2'\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model,'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Fine_Tuned_No_Post2/tokenizer_config.json',\n",
              " 'Fine_Tuned_No_Post2/special_tokens_map.json',\n",
              " 'Fine_Tuned_No_Post2/vocab.txt',\n",
              " 'Fine_Tuned_No_Post2/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}